{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pa1_2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNoKTkQkw+f8uqga193/2t1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":160,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eym7engwH3yR","executionInfo":{"status":"ok","timestamp":1644295555052,"user_tz":300,"elapsed":9519,"user":{"displayName":"冯柄权","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17212043536092825358"}},"outputId":"e7073fbc-1e73-494e-d7a9-588dacfdb886"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: starter in /usr/local/lib/python3.7/dist-packages (0.4.2)\n","Requirement already satisfied: Inirama>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from starter) (0.8.0)\n","Requirement already satisfied: Jinja2>=2.6 in /usr/local/lib/python3.7/dist-packages (from starter) (2.11.3)\n","Requirement already satisfied: oset>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from starter) (0.1.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.6->starter) (2.0.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from oset>=0.1.3->starter) (57.4.0)\n"]}],"source":["!pip install starter\n","import numpy as np\n","from random import getrandbits\n","from unittest import result\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from starter import loadData\n","\n","trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n","trainData = trainData.reshape(3500, -1)\n","validData = validData.reshape(100, -1)\n","testData = testData.reshape(145, -1)\n","trainData = tf.convert_to_tensor(trainData, dtype=tf.float32)\n","validData = tf.convert_to_tensor(validData, dtype=tf.float32)\n","trainTarget = tf.convert_to_tensor(trainTarget, dtype=tf.float32)\n","validTarget = tf.convert_to_tensor(validTarget, dtype=tf.float32)\n","testData = tf.convert_to_tensor(testData, dtype=tf.float32)\n","testTarget = tf.convert_to_tensor(testTarget, dtype=tf.float32)\n","N, D = trainData.shape\n","trainLoss = []\n","validLoss = []\n","trainAcc = []\n","validAcc = []"]},{"cell_type":"code","source":["def ce_loss(y, yHat):\n","  yHat = tf.clip_by_value(yHat, 1e-9, 1.)\n","  return tf.reduce_mean(-tf.reduce_sum(- y * tf.math.log(yHat) - (1 - y) * tf.math.log(1 - yHat)))\n","\n","# sigmoid function\n","def sigmoid(z):\n","  return 1 / (1 + np.exp(-z))\n","\n","# predict y value and returns the probability\n","# the return value is a [n * d][d * 1] = [n * 1] array\n","def predict(w, b, x):\n","  return sigmoid(x @ w + b)\n","\n","# plot\n","def plot_loss(alpha):\n","\n","  plt.figure()\n","  plt.plot(trainLoss, label='Training Loss')\n","  plt.plot(validLoss, label='Validation Loss')\n","  title = \"Traing & Validation Loss vs epochs @ \" + \"%f\" %alpha\n","  plt.title(title)\n","  plt.xlabel(\"epoches\")\n","  plt.ylabel(\"loss\")\n","  plt.legend()\n","  plt.draw()\n","\n","  return\n","\n","def plot_accuracy(reg):\n","\n","  plt.figure()\n","  plt.plot(trainAcc, label='Training Accuracy')\n","  plt.plot(validAcc, label='Validation Accuracy')\n","  title = \"Traing & Validation Accuracy vs epochs @ \" + \"%f\" %reg\n","  plt.title(title)\n","  plt.xlabel(\"epoches\")\n","  plt.ylabel(\"accuracy\")\n","  plt.legend()\n","  plt.draw()\n","\n","  return \n","\n","'''\n","def accuracy(y, yHat):\n","  correctPrediction = tf.equal(tf.argmax(yHat, 1), tf.argmax(y, 1))\n","  accuracy = tf.reduce_mean(tf.cast(correctPrediction, tf.float32))\n","\n","  return accuracy\n","'''\n","def accuracy(y, yHat):\n","  targetHat = (yHat.numpy() > 0.5).astype(float)\n","  acc = (targetHat == y.numpy()).mean()\n","  y = tf.convert_to_tensor(y, dtype=tf.float32)\n","  yHat = tf.convert_to_tensor(yHat, dtype=tf.float32)\n","\n","  return acc\n","\n"],"metadata":{"id":"4IuyyRIBIWf9","executionInfo":{"status":"ok","timestamp":1644295241821,"user_tz":300,"elapsed":150,"user":{"displayName":"冯柄权","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17212043536092825358"}}},"execution_count":155,"outputs":[]},{"cell_type":"code","source":["def shuffle_batch(batchSize):\n","  slicedDb = tf.data.Dataset.from_tensor_slices((trainData, trainTarget))\n","  slicedDb = slicedDb.shuffle(5000).batch(batchSize)\n","\n","  return slicedDb\n","\n","def init_w_b():\n","  w = tf.Variable(tf.random.truncated_normal(shape=(D, 1)), name=\"weight\")\n","  b = tf.Variable(tf.zeros(shape=1), name=\"bias\")\n","\n","  return w, b\n","\n","def train_batch(w, b, x, y, reg, optimizer):\n","  with tf.GradientTape(persistent=True) as g:\n","    yHat = tf.nn.sigmoid(tf.add(tf.matmul(x, w), b))\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = yHat, labels = y) + (reg / 2) * tf.norm(w) ** 2)\n","  \n","  grad = g.gradient(loss, [w, b])\n","  optimizer.apply_gradients(zip(grad, [w, b]))\n","\n","  return w, b"],"metadata":{"id":"vsnTT-t5AZaM","executionInfo":{"status":"ok","timestamp":1644295244062,"user_tz":300,"elapsed":127,"user":{"displayName":"冯柄权","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17212043536092825358"}}},"execution_count":156,"outputs":[]},{"cell_type":"code","source":["# main\n","batchSizeList = [100, 500, 700, 1750]\n","w, b = init_w_b()\n","bt1 = [0.95, 0.99]\n","bt2 = [0.99, 0.9999]\n","e = [1e-09, 1e-04]\n","optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001, beta2=bt2[1])\n","\n","trainLoss.clear()\n","validLoss.clear()\n","trainAcc.clear()\n","validLoss.clear()\n","\n","for i in range(700):\n","  db = shuffle_batch(batchSizeList[1])\n","  for step, (batchX, batchY) in enumerate(db):\n","    w, b = train_batch(w, b, batchX, batchY, 0, optimizer)\n","  \n","  yHat = tf.nn.sigmoid(tf.add(tf.matmul(trainData, w), b))\n","  loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = yHat, labels = trainTarget) + (0 / 2) * tf.norm(w) ** 2)\n","  trainLoss.append(loss)\n","  trainAcc.append(accuracy(trainTarget, yHat))\n","\n","  yHatValid = tf.nn.sigmoid(tf.add(tf.matmul(validData, w), b))\n","  lossValid = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = yHatValid, labels = validTarget) + (0 / 2) * tf.norm(w) ** 2)\n","  validLoss.append(lossValid)\n","  validAcc.append(accuracy(validTarget, yHatValid))\n","\n","plot_loss(0)\n","plot_accuracy(0)\n","\n","yHatTest = tf.nn.sigmoid(tf.add(tf.matmul(testData, w), b))\n","lossTest = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = yHatTest, labels = testTarget) + (0 / 2) * tf.norm(w) ** 2)\n","testAcc = accuracy(testTarget, yHatTest)\n","\n","print(trainAcc[-1])\n","print(\" \")\n","print(validAcc[-1])\n","print(\" \")\n","print(testAcc)\n"],"metadata":{"id":"6UvDwybnUytE"},"execution_count":null,"outputs":[]}]}